{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607a52b7-f3f4-4afe-97e0-9266fdee878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ACE_GRAMMAR=erg.dat\n"
     ]
    }
   ],
   "source": [
    "from ulkb import *   # import ULKB Logic namespace\n",
    "settings.serializer.ulkb.ensure_ascii = False\n",
    "\n",
    "a = TypeVariable('a') # a : *\n",
    "\n",
    "%set_env ACE_GRAMMAR erg.dat\n",
    "\n",
    "import mrs_logic\n",
    "    \n",
    "ctx = mrs_logic.get_current_context()\n",
    "ctx.options['to_ulkb']['universe_type'] = a   # set the type of the (FOL) universe to \"a\"\n",
    "ctx.options['to_ulkb']['drop_uvars'] = True   # delete \"u\" vars\n",
    "ctx.options['to_ulkb']['drop_ivars'] = True   # delete \"i\" vars\n",
    "ctx.options.to_ulkb.mk_q_exists = ['_the_q']\n",
    "ctx.options.to_ulkb.mk_q_forall = ['udef_q']\n",
    "\n",
    "from delphin import itsdb, mrs\n",
    "from delphin.codecs import simplemrs, mrx, mrsprolog\n",
    "import tree_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5afa61-8933-459b-86dd-86586b9999c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt[0]: Charles hates no one that Agatha hates.\n",
      "[ TOP: h0\n",
      "  INDEX: e2\n",
      "  RELS: < [ proper_q LBL: h4 ARG0: x3 RSTR: h5 BODY: h6 ]\n",
      "          [ named LBL: h7 ARG0: x3 CARG: \"Charles\" ]\n",
      "          [ _hate_v_1 LBL: h1 ARG0: e2 ARG1: x3 ARG2: x9 ]\n",
      "          [ person LBL: h10 ARG0: x9 ]\n",
      "          [ _no_q LBL: h11 ARG0: x9 RSTR: h12 BODY: h13 ]\n",
      "          [ proper_q LBL: h14 ARG0: x15 RSTR: h16 BODY: h17 ]\n",
      "          [ named LBL: h18 ARG0: x15 CARG: \"Agatha\" ]\n",
      "          [ _hate_v_1 LBL: h10 ARG0: e20 ARG1: x15 ARG2: x9 ] >\n",
      "  HCONS: < h0 qeq h1 h5 qeq h7 h12 qeq h10 h16 qeq h18 > ]\n",
      "reading:0 solutions:5\n",
      "(∀ x9, (∃ x15, Agatha = x15 ∧ (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9)) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x15, Agatha = x15 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x15, Agatha = x15 ∧ (∃ x3, Charles = x3 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∀ x9, (∃ x15, Agatha = x15 ∧ (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9)) → ¬(∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∃ x15, Agatha = x15 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "reading:1 solutions:5\n",
      "(∀ x9, (∃ x17, Agatha = x17 ∧ (∃ e22, generic_entity x9 ∧ card 1 x9 ∧ _hate_v_1 e22 x17 x9)) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∀ x9, (∃ x17, Agatha = x17 ∧ (∃ e22, generic_entity x9 ∧ card 1 x9 ∧ _hate_v_1 e22 x17 x9)) → ¬(∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∃ x17, Agatha = x17 ∧ (∀ x9, (∃ e22, generic_entity x9 ∧ card 1 x9 ∧ _hate_v_1 e22 x17 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x17, Agatha = x17 ∧ (∀ x9, (∃ e22, generic_entity x9 ∧ card 1 x9 ∧ _hate_v_1 e22 x17 x9) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x17, Agatha = x17 ∧ (∃ x3, Charles = x3 ∧ (∀ x9, (∃ e22, generic_entity x9 ∧ card 1 x9 ∧ _hate_v_1 e22 x17 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "reading:2 solutions:5\n",
      "(∀ x9, (∃ x15, Agatha = x15 ∧ (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9)) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x15, Agatha = x15 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ x3, Charles = x3 ∧ (∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x15, Agatha = x15 ∧ (∃ x3, Charles = x3 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∀ x9, (∃ x15, Agatha = x15 ∧ (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9)) → ¬(∃ e2, _hate_v_1 e2 x3 x9))) : 𝔹\n",
      "(∃ x3, Charles = x3 ∧ (∃ x15, Agatha = x15 ∧ (∀ x9, (∃ e20, person x9 ∧ _hate_v_1 e20 x15 x9) → ¬(∃ e2, _hate_v_1 e2 x3 x9)))) : 𝔹\n"
     ]
    }
   ],
   "source": [
    "sentences = ['let us go to the store.', 'I am going to store, lets go.']\n",
    "sentences = ['Every child sings.', 'All the children sing.','All children sing.',\n",
    "             'Some children sing.','Some children sing.', 'Children sing.','The child sings.']\n",
    "sentences = ['My friend and neighbor often helps me.',\n",
    "             'it is not the case that every representative of a company saw a sample.']\n",
    "sentences = ['every dog that barks is happy','every dog that is happy barks']\n",
    "sentences = ['John and Mary are carrying a piano']\n",
    "sentences = ['Charles hates no one that Agatha hates.'] \n",
    "\n",
    "res, ers = [], []\n",
    "for t,txt in enumerate(sentences):\n",
    "    print(f\"txt[{t}]: {txt}\")\n",
    "    for i,mrs in enumerate(mrs_logic.parse(txt)):\n",
    "        if i < 1: print(mrs)\n",
    "        if i > 2:\n",
    "            continue\n",
    "        try:\n",
    "            solver = mrs_logic.Solver(mrs)\n",
    "        except mrs_logic.SolverError as e:\n",
    "            print(i,e)\n",
    "            continue\n",
    "        with open(f\"{t}-{i}.mrs.pl\", \"w\") as fp:\n",
    "            pass\n",
    "            print(mrsprolog.encode(mrs, indent=True), file = fp)\n",
    "        n = solver.count_solutions()\n",
    "        print(f\"reading:{i} solutions:{n}\")\n",
    "        for sol in solver.iterate_solutions():\n",
    "            res = sol.to_ulkb()\n",
    "            print(res.serialize(show_types=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223fdb71-fb6a-4e15-821e-e5be1f9ca5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ar/r/mrs-logic/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "07/25/2024 21:29:27 - INFO - \t missing_keys: []\n",
      "07/25/2024 21:29:27 - INFO - \t unexpected_keys: []\n",
      "07/25/2024 21:29:27 - INFO - \t mismatched_keys: []\n",
      "07/25/2024 21:29:27 - INFO - \t error_msgs: []\n",
      "07/25/2024 21:29:27 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "07/25/2024 21:29:27 - INFO - \t Tokenize 9 inputs...\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 250.29 examples/s]\n",
      "07/25/2024 21:29:28 - INFO - \t ***** Running Inference on 9 texts *****\n",
      "Inference: 100%|███████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 12.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CorefResult(text=\"Someone who lives in Dreadbury killed Agatha.\", clusters=[]),\n",
       " CorefResult(text=\"Agatha, the butler, and Charles live in Dreadbury,...\", clusters=[]),\n",
       " CorefResult(text=\"A killer always hates his victim, and is never ric...\", clusters=[['A killer', 'his', 'his']]),\n",
       " CorefResult(text=\"Charles hates no one that Aunt Agatha hates.\", clusters=[]),\n",
       " CorefResult(text=\"Agatha hates everyone except the butler\", clusters=[]),\n",
       " CorefResult(text=\"The butler hates everyone not richer than Aunt Aga...\", clusters=[]),\n",
       " CorefResult(text=\"The butler hates everyone Aunt Agatha hates\", clusters=[]),\n",
       " CorefResult(text=\"No one hates everyone\", clusters=[]),\n",
       " CorefResult(text=\"Agatha is not the butler\", clusters=[])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pypi.org/project/fastcoref/\n",
    "\n",
    "from fastcoref import FCoref\n",
    "\n",
    "model = FCoref()\n",
    "\n",
    "txt = ['Someone who lives in Dreadbury killed Agatha.',\n",
    "       'Agatha, the butler, and Charles live in Dreadbury, and are the only people who live therein.',\n",
    "       'A killer always hates his victim, and is never richer than his victim',\n",
    "       'Charles hates no one that Aunt Agatha hates.',\n",
    "       'Agatha hates everyone except the butler',\n",
    "       'The butler hates everyone not richer than Aunt Agatha',\n",
    "       'The butler hates everyone Aunt Agatha hates',\n",
    "       'No one hates everyone',\n",
    "       'Agatha is not the butler']\n",
    "\n",
    "preds = model.predict(texts= txt)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06e14ffc-9f7a-4e6c-a20a-b272dcc4481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 18:24:55 - INFO - \t missing_keys: []\n",
      "07/25/2024 18:24:55 - INFO - \t unexpected_keys: []\n",
      "07/25/2024 18:24:55 - INFO - \t mismatched_keys: []\n",
      "07/25/2024 18:24:55 - INFO - \t error_msgs: []\n",
      "07/25/2024 18:24:55 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "07/25/2024 18:24:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 203.95 examples/s]\n",
      "07/25/2024 18:24:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the patient\n",
      "his\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import spacy_component\n",
    "import spacy\n",
    "\n",
    "text = 'The nurse notified the patient that his shift would be ending in an hour.'\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"fastcoref\")\n",
    "\n",
    "doc = nlp(text)\n",
    "for cluster in doc._.coref_clusters:\n",
    "    for a,b in cluster:\n",
    "        print(text[a:b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4684c8-3af9-4388-a314-336ae9f7f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for m in open(\"ws201.txt\"):\n",
    "    mrs = simplemrs.decode(m)\n",
    "    try:\n",
    "        s = mrs_logic.Solver(mrs)\n",
    "        res.append(s.count_solutions())\n",
    "    except:\n",
    "        continue\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f0182-02a8-497c-9c1c-4a9d4020c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphin import itsdb, mrs\n",
    "from delphin.codecs import simplemrs, mrx, mrsprolog\n",
    "import tree_algorithm\n",
    "\n",
    "sentences = ['Every child sings.', 'All the children sing.','All children sing.',\n",
    "             'Some children sing.','Some children sing.',\n",
    "             'Children sing.','The child sings.']\n",
    "sentences = ['My friend and neighbor often helps me.']\n",
    "sentences = ['dogs that bark are happy','dogs that are happy barks']\n",
    "\n",
    "res, ers = [], []\n",
    "for txt in sentences:\n",
    "    for i,mrs in enumerate(mrs_logic.parse(txt)):\n",
    "        solver = mrs_logic.Solver(mrs)\n",
    "        with open(f\"{i}.mrs.pl\", \"w\") as fp:\n",
    "            print(mrsprolog.encode(mrs, indent=True), file = fp)\n",
    "        n = solver.count_solutions()\n",
    "        print(f\"reading:{i} solutions:{n}\")\n",
    "        for sol in solver.iterate_solutions():\n",
    "            res = sol.to_ulkb()\n",
    "            print(res.serialize(show_types=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
